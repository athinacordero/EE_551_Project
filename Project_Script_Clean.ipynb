{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Steps\n",
    "1. 'Unpack Data'\n",
    "2. Put data into easy to deal with format (Pandas dataframe?)\n",
    "3. Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "- Sklearn\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Keras\n",
    "- Tensorflow\n",
    "- pydot (for visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "- train_data (dataframe)\n",
    "- test data (dataframe)\n",
    "- X (training data from train_data [slice of dataframe])\n",
    "- Y (training data from train_data [slice of dataframe])\n",
    "- X_test (test data from test_data)\n",
    "\n",
    "***No Y_test is given by Kaggle, Kaggle hides the solution to the test data to keep users honest in the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "train_data = pd.read_csv('House_Data/train.csv')\n",
    "test_data = pd.read_csv('House_Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of categorical variables\n",
    "\n",
    "def find_categorical(data):\n",
    "    list_categorical = []\n",
    "    for col in list(data.columns):\n",
    "        if str(data[col].dtype) != 'int64' and str(data[col].dtype) != 'float64':\n",
    "            list_categorical.append(col)\n",
    "    return list_categorical\n",
    "\n",
    "categorical_columns = find_categorical(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical variables with quantitative ones (via one hot encoding)\n",
    "\n",
    "def replace_categorical(data,categorical_columns):\n",
    "    for col in categorical_columns:\n",
    "        \n",
    "        # create new dataframe from one hot encoding\n",
    "        # use pd.get_dummies instead of OneHotEncoder because: \n",
    "        # https://medium.com/@guaisang/handling-categorical-features-get-dummies-onehotencoder-and-multicollinearity-f9d473a40417\n",
    "        one_hot = pd.DataFrame(pd.get_dummies(data[col]))\n",
    "        \n",
    "        # rename dataframe columns to add the original column name so we know where the new column came from\n",
    "        one_hot.columns = [str(one_hot_column) + '_' + col for one_hot_column in one_hot.columns]\n",
    "        \n",
    "        # join the one-hot column to the original dataframe\n",
    "        data = data.join(one_hot)\n",
    "        \n",
    "        data = data.drop(col,axis=1)\n",
    "        # return the new table\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    # fill the NaN with the mean of the column\n",
    "    data.fillna(data.mean(),inplace=True)\n",
    "    # Drop the 'Id' column since we already have an index and do not need it messing up our model\n",
    "    data = data.drop('Id',axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = replace_categorical(train_data,categorical_columns)\n",
    "train_data = prep_data(train_data)\n",
    "\n",
    "test_data = replace_categorical(test_data,categorical_columns)\n",
    "test_data.fillna(test_data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for the columns that are in train and aren't in test\n",
    "def check_leftover(data1,data2):\n",
    "    non_overlap = []\n",
    "    for col in data1.columns:\n",
    "        if col not in list(data2.columns):\n",
    "            non_overlap.append(col)\n",
    "    return non_overlap\n",
    "\n",
    "columns_in_train_not_in_test = check_leftover(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train X and Y and test X\n",
    "def train_data_X_and_Y(data,columns_missing,goal_column):\n",
    "    X = data.drop(columns_missing,axis=1)\n",
    "    Y = data[goal_column]\n",
    "    return X,Y\n",
    "\n",
    "X,Y = train_data_X_and_Y(train_data,columns_in_train_not_in_test,'SalePrice')\n",
    "X_test = test_data.drop('Id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multilinear regression model using sci-kit learn\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X,Y)\n",
    "# print('Intercept: \\n', model.intercept_)\n",
    "# print('Coefficients: \\n', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Kaggle submission csv\n",
    "def create_submission(data, prediction, pred_num, prediction_column='SalePrice'):\n",
    "    submission = data['Id']\n",
    "    submission = pd.DataFrame(submission)\n",
    "    submission[prediction_column] = prediction\n",
    "    sub_str = 'submission' + str(pred_num) + '.csv'\n",
    "    submission.to_csv(sub_str,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(X_test)\n",
    "create_submission(test_data,Y_prediction,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Trial Summary -- Simple Linear Regression landed me with a score of ~.4639 on Kaggle... Let's see how we can improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different type of linear model (Least Absolute Shrinkage Selector Operator), which automatically does feature selection\n",
    "\n",
    "# alpha balances the amount of emphasis given to minimizing RSS vs minimizing sum of square of coefficients\n",
    "lasso = linear_model.Lasso(alpha=10)\n",
    "lasso.fit(X,Y)\n",
    "y_lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_lasso_pred,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Trial Summary - Lasso Regression landed me with a ~.4611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning model with Keras\n",
    "\n",
    "def deep_learning_model():\n",
    "    model = Sequential()\n",
    "    # input dimensions is the number of independent variables (all the columns in train_data except for SalePrice)\n",
    "    # activation = output of node (neuron) = exponential linear unit (after testing it yielded better results)\n",
    "    model.add(Dense(135, input_dim=270, kernel_initializer='normal', activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model (configure for training)\n",
    "    # optimizer 'adam' was chosen because it (on average) is the speediest\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=deep_learning_model, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "estimator.fit(X,Y)\n",
    "y_keras_pred = estimator.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_keras_pred,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Trial Summary -- Big improvement! Deep learning received a score on Kaggle of 0.207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_model2():\n",
    "    model = Sequential()\n",
    "    # input dimensions is the number of independent variables (all the columns in train_data except for SalePrice)\n",
    "    # activation = output of node (neuron) = exponential linear unit (after testing it yielded better results)\n",
    "    model.add(Dense(135, input_dim=270, kernel_initializer='normal', activation='elu'))\n",
    "    model.add(Dense(135, kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model (configure for training)\n",
    "    # optimizer 'adam' was chosen because it (on average) is the speediest\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator2 = KerasRegressor(build_fn=deep_learning_model2, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "estimator2.fit(X,Y)\n",
    "y_keras_pred2 = estimator2.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_keras_pred2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_learning_model2().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Trial-- added another layer to my neural network, which gave me a score on Kaggle of 0.164"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
