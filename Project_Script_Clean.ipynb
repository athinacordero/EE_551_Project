{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Steps\n",
    "1. 'Unpack Data'\n",
    "2. Put data into easy to deal with format (Pandas dataframe?)\n",
    "3. Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "- Sklearn\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Keras\n",
    "- Tensorflow\n",
    "- pydot (for visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global variables\n",
    "- train_data (dataframe)\n",
    "- test data (dataframe)\n",
    "- X (training data from train_data [slice of dataframe])\n",
    "- Y (training data from train_data [slice of dataframe])\n",
    "- X_test (test data from test_data)\n",
    "\n",
    "***No Y_test is given by Kaggle, Kaggle hides the solution to the test data to keep users honest in the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "train_data = pd.read_csv('House_Data/train.csv')\n",
    "test_data = pd.read_csv('House_Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list of categorical variables\n",
    "\n",
    "def find_categorical(data):\n",
    "    list_categorical = []\n",
    "    for col in list(data.columns):\n",
    "        if str(data[col].dtype) != 'int64' and str(data[col].dtype) != 'float64':\n",
    "            list_categorical.append(col)\n",
    "    return list_categorical\n",
    "\n",
    "categorical_columns = find_categorical(train_data)\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical variables with quantitative ones (via one hot encoding)\n",
    "\n",
    "def replace_categorical(data,categorical_columns):\n",
    "    for col in categorical_columns:\n",
    "        \n",
    "        #create new dataframe from one hot encoding\n",
    "        one_hot = pd.DataFrame(pd.get_dummies(data[col]))\n",
    "        \n",
    "        # rename dataframe columns to add the original column name so we know where the new column came from\n",
    "        one_hot.columns = [str(one_hot_column) + '_' + col for one_hot_column in one_hot.columns]\n",
    "        \n",
    "        # join the one-hot column to the original dataframe\n",
    "        data = data.join(one_hot)\n",
    "        if 'C (all)_' + col in data.columns:\n",
    "            to_drop = 'C (all)_' + col\n",
    "            data.drop(to_drop, axis=1)\n",
    "        \n",
    "        data = data.drop(col,axis=1)\n",
    "        # return the new table\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    # fill the NaN with the mean of the column\n",
    "    data.fillna(data.mean(),inplace=True)\n",
    "    # Drop the 'Id' column since we already have an index and do not need it messing up our model\n",
    "    data = data.drop('Id',axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = replace_categorical(train_data,categorical_columns)\n",
    "train_data = prep_data(train_data)\n",
    "\n",
    "test_data = replace_categorical(test_data,categorical_columns)\n",
    "test_data.fillna(test_data.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_overlap(data1,data2):\n",
    "    non_overlap = []\n",
    "    for col in data1.columns:\n",
    "        if col not in list(data2.columns):\n",
    "            non_overlap.append(col)\n",
    "    return non_overlap\n",
    "\n",
    "columns_in_train_not_in_test = check_overlap(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_X_and_Y(data,columns_missing,goal_column):\n",
    "    X = data.drop(columns_missing,axis=1)\n",
    "    Y = data[goal_column]\n",
    "    return X,Y\n",
    "\n",
    "X,Y = train_data_X_and_Y(train_data,columns_in_train_not_in_test,'SalePrice')\n",
    "X_test = test_data.drop('Id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: \n",
      " 663934.2701922326\n",
      "Coefficients: \n",
      " [-1.10718919e+02 -9.03559657e+01  5.49465066e-01  7.77551036e+03\n",
      "  5.26389579e+03  2.24726804e+02  5.87612163e+01  2.48382139e+01\n",
      "  3.92033626e+00  5.13753472e+00 -2.49032345e+00  6.56756279e+00\n",
      "  2.10764335e+01  3.19424617e+01 -3.04818321e+01  2.25369886e+01\n",
      "  3.71108750e+03  6.32918270e+02  5.66626789e+03  1.11295310e+03\n",
      " -2.99138526e+03 -1.23904646e+04  2.70879556e+03  4.35529269e+03\n",
      " -5.35183742e+01  1.02629253e+04  2.56397430e+00  1.89713056e+01\n",
      "  7.41281932e+00  1.62544596e+00  4.86367132e+01  2.81403620e+01\n",
      "  7.43703885e+01  3.66781420e+00 -3.63675229e+02 -6.87495344e+02\n",
      " -2.42837411e+04  1.16674336e+04  4.30540086e+03  5.82816828e+03\n",
      "  2.48273838e+03 -1.52657937e+04  1.52657937e+04  1.19511989e+03\n",
      "  2.55784423e+03  2.24676808e+03  4.80347316e+03 -1.07818332e+04\n",
      "  3.73159201e+03 -6.93839759e+03  6.08723310e+03 -4.36090358e+03\n",
      "  5.21206807e+03  6.16371120e+04  4.07883733e+03  1.42973905e+04\n",
      " -5.60548460e+03 -1.45963412e+04  1.82559799e+03  2.68815521e+03\n",
      "  1.02449673e+04 -1.29331226e+04  2.12465585e+03 -2.79486365e+03\n",
      "  1.10196001e+03 -4.84761050e+03 -1.04151435e+04 -4.98266590e+03\n",
      "  1.68534899e+04 -1.96764531e+04 -8.48844409e+03 -1.10658271e+04\n",
      " -7.70117145e+03 -1.65042700e+04 -1.42082617e+04  9.82013351e+03\n",
      " -1.64280488e+04  3.73043290e+04  2.87463626e+04 -1.40037370e+04\n",
      " -5.17665632e+03 -9.96018346e+03  9.90573360e+01  4.96144067e+03\n",
      "  4.63318296e+04 -4.27331702e+03  3.18339529e+03 -7.47639058e+03\n",
      "  3.52877888e+02  1.03980369e+04  6.38050726e+03  9.23905972e+03\n",
      " -1.66139445e+04  5.56462998e+03 -9.75675463e+03  1.91197804e+03\n",
      "  1.47846440e+04  1.01000370e+04  1.22851262e+03  6.92575899e+04\n",
      " -1.88252124e+05  7.71193547e+03  9.60553198e+03  3.30911055e+03\n",
      " -1.22753851e+04 -8.35119294e+03  1.42849283e+04  2.33505462e+04\n",
      "  2.12226411e+04  4.15219146e+03  8.22566755e+03  1.54608625e+04\n",
      "  2.19918516e+04  5.05194317e+04 -2.25814533e+04 -1.74638243e+04\n",
      " -2.13864556e+04 -9.50088751e+03  2.04131889e+04  1.11427929e+05\n",
      "  5.29341296e+04  1.06234158e+05  1.74113924e+05  1.44848795e+04\n",
      " -1.26877676e+04 -3.62544144e+03  1.55792510e+04  8.75015086e+03\n",
      "  4.44575365e+03 -2.14480902e+03  4.18116682e+03  3.90131225e+03\n",
      " -1.12224325e+03 -1.10092983e+03 -3.77552453e+03 -1.49974303e+03\n",
      "  1.35639902e+04  2.11624786e+04  1.34494956e+04  2.08969325e+04\n",
      "  8.75015086e+03  2.34923888e+04  2.15374355e+04  3.03812072e+04\n",
      "  2.01969820e+04  1.79080077e+04 -9.80744315e+02  6.08340487e+03\n",
      "  2.52948042e+04  2.46151505e+04  1.49318206e+04 -4.86430322e+03\n",
      "  3.52541060e+02  5.54339219e+03  6.06269852e+03  1.07485887e+04\n",
      "  4.19613667e+03 -6.84817619e+03 -8.09654922e+03 -4.22600223e+03\n",
      "  3.21386967e+03 -1.18956804e+03  4.31798201e+02  1.76990240e+03\n",
      "  2.13027439e+03  6.22867840e+03  6.02917792e+03 -9.98907085e+03\n",
      "  1.12880501e+04 -1.56871100e+04  1.85110767e+04  1.65113558e+03\n",
      " -2.58414128e+03  5.60283546e+02 -5.73659396e+03 -4.97707399e+03\n",
      "  2.89423812e+04 -9.03586622e+01  1.17081079e+04  2.70405383e+04\n",
      "  8.35498529e+03  5.72564693e+03  3.00389658e+03  3.21660674e+03\n",
      "  8.36949624e+03  2.15793175e+02  4.19771757e+03 -8.65155767e+02\n",
      " -8.36816303e+03 -1.37887058e+04  1.70457220e+03 -1.71308540e+04\n",
      " -1.15924603e+04 -8.38158338e+03  2.16029652e+04  2.90700290e+04\n",
      "  1.77363401e+04  3.95232076e+04  4.52036143e+03  3.68062719e+03\n",
      "  1.71513394e+02 -9.87907476e+03  1.50657274e+03 -6.68830551e+02\n",
      "  6.68830551e+02  1.60070144e+03  2.40586099e+03  9.94552845e+03\n",
      " -2.16407270e+03  1.82110039e+04 -5.35200870e+03 -6.69320693e+03\n",
      " -6.16578830e+03  5.62783279e+03  1.95217370e+03  7.89153679e+03\n",
      "  1.16627102e+04  1.21332663e+04 -6.06397214e+04  2.13722016e+04\n",
      " -1.99426760e+03 -5.58814396e+03 -2.14164638e+03  7.15082290e+03\n",
      " -8.91063481e+02  1.28613673e+03  2.14911436e+04  2.82755319e+04\n",
      "  2.14160346e+04  2.72489564e+04  2.25346511e+04  4.22069574e+04\n",
      "  3.90249982e+04  4.10204988e+04 -1.27388169e+05 -1.10989153e+05\n",
      " -1.48342581e+05 -1.17845113e+05 -6.57193978e+04  4.47360100e+04\n",
      "  5.16815810e+04  4.76113322e+04  4.39429289e+04 -8.46407428e+01\n",
      " -1.15118179e+03  1.23582253e+03  1.13138369e+05 -1.25365741e+05\n",
      " -6.72382819e+03 -2.36315496e+03  1.78284548e+02 -6.31673176e+03\n",
      " -7.64375677e+04  3.77397564e+03 -2.26535278e+03 -1.24380384e+04\n",
      "  6.27277573e+03  1.61121205e+04  6.31436055e+03 -7.42832837e+03\n",
      " -1.56606584e+04  2.29205795e+04 -2.50396177e+03 -1.35888493e+04\n",
      " -1.96313725e+03 -3.32697707e+03  1.47362533e+04  1.26402421e+03\n",
      "  6.13696591e+03 -1.68471291e+04]\n"
     ]
    }
   ],
   "source": [
    "# Create multilinear regression model using sci-kit learn\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(X,Y)\n",
    "print('Intercept: \\n', model.intercept_)\n",
    "print('Coefficients: \\n', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission(data, prediction, pred_num, prediction_column='SalePrice'):\n",
    "    submission = data['Id']\n",
    "    submission = pd.DataFrame(submission)\n",
    "    submission[prediction_column] = prediction\n",
    "    sub_str = 'submission' + str(pred_num) + '.csv'\n",
    "    submission.to_csv(sub_str,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction = model.predict(X_test)\n",
    "create_submission(test_data,Y_prediction,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Trial Summary -- Simple Linear Regression landed me with a score of ~.4639 on Kaggle... Let's see how we can improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different type of linear model (Least Absolute Shrinkage Selector Operator), which automatically does feature selection\n",
    "\n",
    "# alpha balances the amount of emphasis given to minimizing RSS vs minimizing sum of square of coefficients\n",
    "lasso = linear_model.Lasso(alpha=10)\n",
    "lasso.fit(X,Y)\n",
    "y_lasso_pred = lasso.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_lasso_pred,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Trial Summary - Lasso Regression landed me with a ~.4611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning model with Keras\n",
    "\n",
    "def deep_learning_model():\n",
    "    model = Sequential()\n",
    "    # input dimensions is the number of independent variables (all the columns in train_data except for SalePrice)\n",
    "    # activation = output of node (neuron) = exponential linear unit (after testing it yielded better results)\n",
    "    model.add(Dense(135, input_dim=270, kernel_initializer='normal', activation='elu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model (configure for training)\n",
    "    # optimizer 'adam' was chosen because it (on average) is the speediest\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=deep_learning_model, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "estimator.fit(X,Y)\n",
    "y_keras_pred = estimator.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_keras_pred,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Trial Summary -- Big improvement! Deep learning received a score on Kaggle of 0.207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_learning_model2():\n",
    "    model = Sequential()\n",
    "    # input dimensions is the number of independent variables (all the columns in train_data except for SalePrice)\n",
    "    # activation = output of node (neuron) = exponential linear unit (after testing it yielded better results)\n",
    "    model.add(Dense(135, input_dim=270, kernel_initializer='normal', activation='elu'))\n",
    "    model.add(Dense(135, kernel_initializer='normal'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Compile model (configure for training)\n",
    "    # optimizer 'adam' was chosen because it (on average) is the speediest\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimator2 = KerasRegressor(build_fn=deep_learning_model2, epochs=100, batch_size=5, verbose=0)\n",
    "\n",
    "estimator2.fit(X,Y)\n",
    "y_keras_pred2 = estimator2.predict(X_test)\n",
    "\n",
    "create_submission(test_data,y_keras_pred2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 135)               36585     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 135)               18360     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 136       \n",
      "=================================================================\n",
      "Total params: 55,081\n",
      "Trainable params: 55,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_learning_model2().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Trial-- added another layer to my neural network, which gave me a score on Kaggle of 0.164"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
